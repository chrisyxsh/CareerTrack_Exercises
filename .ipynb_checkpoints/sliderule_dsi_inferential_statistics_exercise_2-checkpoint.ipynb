{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/us_job_market_discrimination.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cc0300cb7157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/us_job_market_discrimination.dta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/stata.py\u001b[0m in \u001b[0;36mread_stata\u001b[0;34m(filepath_or_buffer, convert_dates, convert_categoricals, encoding, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator)\u001b[0m\n\u001b[1;32m    172\u001b[0m                          \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                          \u001b[0morder_categoricals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_categoricals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                          chunksize=chunksize, encoding=encoding)\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/stata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buf, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, encoding, chunksize)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0;31m# Copy to BytesIO, and ensure no encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/us_job_market_discrimination.dta'"
     ]
    }
   ],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bfb11f4b461e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# number of callbacks for black-sounding names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"White Call:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Black Call:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "print(\"White Call:\",sum(data[data.race=='w'].call))\n",
    "print(\"Black Call:\",sum(data[data.race=='b'].call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question I - What test is appropriate for this problem? Does CLT apply?\n",
    "Callings of resumes is a binomial distribution or a poisson distribution. CLT can apply to it for calculating it's test statistics such as call back percentage, and the mean and confidence interval of the call back percentage. We can use bootstrap method and frequentist test method to do statistical hypothesis test. \n",
    "\n",
    "#### Hypothesis for Bootstrap hypothesis test\n",
    "##### Null Hypothesis\n",
    "    There is no any difference for calling back on names of black-like or white-like. The sample shown that the number of black-call is lower than the number of white-call, is just by chance.\n",
    "##### Alternative Hypothesis\n",
    "    There is obvious difference of calling back between black-sounding names and white-sounding names. There is highly probability of race bias.\n",
    "### Question II - Hypothesis\n",
    "#### Hypothesis for Z-test\n",
    "##### Null Hypothesis I\n",
    "    There is no any bias for calling back on names of black-like. The sample shown that the number of black-call is lower than the number of white-call, is just by chance.\n",
    "##### Null Hypothesis II\n",
    "    There is no any bias for calling back on names of white-like. The sample shown that the number of white-call is higher than the number of black-call, is just by chance.\n",
    "##### Alternative Hypothesis I\n",
    "    There is significant difference of callback between black and average of population. The difference may caused by race bias for the obvious difference contents among resumes are the black-sounding names.\n",
    "##### Alternative Hypothesis II\n",
    "    There is significant difference of callback between white and average of population. The difference may caused by race bias for the obvious difference contents among resumes are the white-sounding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_call = w.call.values\n",
    "b_call = b.call.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution to Q3 here\n",
    "def per_callback(data):\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def bs_replicate_1d(data,func):\n",
    "    return func(np.random.choice(data,size=len(data)))\n",
    "\n",
    "def bs_replicate_draw(data,func,size=1):\n",
    "    bs_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bs_replicate_1d(data,func)\n",
    "    return bs_replicates\n",
    "\n",
    "def mar_err_95(data,t_value,true_mean):\n",
    "    sem = np.std(data)/len(data)**0.5\n",
    "    return t_value*(np.mean(data)-true_mean)/sem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Hypothesis test\n",
    "    1. At first we will use bootstrap method to simulate each 100 times drawing sample for black-sounding names and white-sounding names, and calculate the callback percentage for each drawing.\n",
    "    2. Then we use the two arrays of callback percentage to calculate their gap(callback_gap) as the test statistic.\n",
    "    3. We concatenate those two arrays to calculate the mean, and use it to shift the two arrays.\n",
    "    4. We simulate 10000 times experiments with each shifted array, and calculate the mean of those replicates. Then we can calculate the gap(bs_replicates) of the mean between two groups of replicates.\n",
    "    5. At last we can calculate the p-value of the bs_replicates being greater or eaual to callback_gap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value =  0.0\n"
     ]
    }
   ],
   "source": [
    "callback_gap = per_callback(w_call)- per_callback(b_call)\n",
    "\n",
    "callback_b = bs_replicate_draw(b_call,per_callback,100)\n",
    "callback_w = bs_replicate_draw(w_call,per_callback,100)\n",
    "\n",
    "b_mean = np.mean(callback_b)\n",
    "w_mean = np.mean(callback_w)\n",
    "\n",
    "callback_conc = np.concatenate((callback_b,callback_w))\n",
    "callback_mean = np.mean(callback_conc)\n",
    "\n",
    "callback_b_shifted = callback_b - b_mean + callback_mean\n",
    "callback_w_shifted = callback_w - w_mean + callback_mean\n",
    "\n",
    "bs_replicates_b = bs_replicate_draw(callback_b_shifted,np.mean,10000)\n",
    "bs_replicates_w = bs_replicate_draw(callback_w_shifted,np.mean,10000)\n",
    "\n",
    "bs_replicates = bs_replicates_w - bs_replicates_b\n",
    "\n",
    "p = sum(bs_replicates >= callback_gap)/len(bs_replicates)\n",
    "print(\"p-value = \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value equals zero means the probability is very very small. The results reject the null hypothesis and support the alternative hypothesis, that is there is obvious difference on resume calling back between black-sounding names and white-sounding names. The race bias highly probably exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-test\n",
    "\n",
    "We use bootstrap method to simulate 100000 times experiments to calculate estimate callback percentage and take it's distribution as population distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_call = data.call.values\n",
    "bs_rep_pop = bs_replicate_draw(pop_call,per_callback,200000)\n",
    "pop_mean = np.mean(bs_rep_pop)\n",
    "pop_std = np.std(bs_rep_pop)\n",
    "pop_conf_int = np.percentile(bs_rep_pop,[2.5,97.5])\n",
    "pop_mar_err = critical_t*np.std(bs_rep_pop)/len(bs_rep_pop)**0.5\n",
    "print(\"Estimate the mean of population for callback percentage : \", pop_mean)\n",
    "print(\"Estimate the standard deviation of population for callback percentage : \", pop_std)\n",
    "print(\"Estimate the confidence interval of population for callback percentage : \", pop_conf_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(bs_rep_pop,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_callback = sum(b_call)/len(b_call)\n",
    "w_callback = sum(w_call)/len(w_call)\n",
    "\n",
    "z_score_b = (b_callback - pop_mean)/pop_std\n",
    "z_score_w = (w_callback - pop_mean)/pop_std\n",
    "\n",
    "print(\"z-score for black call: \", z_score_b)\n",
    "print(\"z-score for white call: \", z_score_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the callback percentage distribution is symmetric, via checing Standard Normal (z) Distribution table, we know that P(Z<= -3.5) and P(Z>=3.5) are both 0.0001. \n",
    "\n",
    "The z-score of black call is near -4.11 which is less than -3.5, then we can reject the \"Null hypothesis I\" and take \"Alternative hypothesis I\". So we consider there is obvious difference for resume calling back percentage between black-sounding names and average pupulation. There is highly probability of race bias to make the resume calling back percentage of black-sounding names is quite **lower** than average level of population.\n",
    "\n",
    "The z-score of white call is also near 4.11, then the situation is similar as blackcall that we can reject \"Null hypothesis II\" and take \"Alternative hypothesis II\". The difference is that there is highly probability of race bias to make the resume calling back percentage of white-sounding names is quite **higher** than average level of population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question IV - Write a story describing the statistical significance in the context or the original problem.\n",
    "    The HR director of A company received complaints from board members of the highly uneven race proportion of employees. The HR-D has confidence that the HR department is working with the high professional process. \"We choose people with the business needs of the company, that's the key factor for hiring someone useful.\" The HR-D thought. For reason of being professional, the HR-D still outsourced a third-party consultant company to do a survey. \n",
    "    \n",
    "    The consultant company randomly assigned identical résumés to black-sounding or white-sounding names, and sent them to A company's HR department for several months, and had been observing the impact on requests for interviews from employers. Finally the result showed that there was an obvious statistically significant difference on callback between the resumes of black-sounding names and those of white-sounding names. \n",
    "    \n",
    "    \"We need to review our HR process now.\" The HR-D wrote to the board members of A company.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question V - Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the result of the analysis above shows that in the sample data, race/name is the most important factor in callback success. But it doesn't mean this is exactly the case in practical. We need to draw more samples for other races such as Spanish, Aisa. Thus we can be much more closer to the true population distribution of callback, and we can have higher accuracy on statistical frequentist test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
